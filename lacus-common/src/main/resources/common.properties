# resource storage type
resource.storage.type=HDFS
# 文件上传hdfs基础路径
resource.storage.upload.base.path=/lacus/upload
# hdfs username
hadoop.username=casey
# defaultFS
hdfs.defaultFS=hdfs://hadoop1:9000
# if resource manager HA is disabled, keep this value empty
yarn.resourcemanager.ha.rm.ids=
# if resource manager HA is enabled or not use resource manager, please keep the default value;
# if resource manager is single, you only need to replace hadoop1 to actual resource manager hostname
yarn.application.status.address=http://hadoop1:%s/ws/v1/cluster/apps/%s
# job history status url
yarn.job.history.status.address=http://hadoop1:19888/ws/v1/history/mapreduce/jobs/%s
# yarn rest api address
yarn.restapi-address:http://hadoop2:8088/
# yarn node rest api address
yarn.node-address:http://hadoop2:8088/cluster/nodes
# yarn resource manager port
yarn.resource.manager.httpaddress.port=8088
sudo.enable=true
data.basedir.path=/Users/casey/tmp/data/
# 是否启用kerberos认证
hadoop.security.authentication.startup.state=false
java.security.krb5.conf.path=
login.user.keytab.path=
login.user.keytab.username=
# kafka servers
kafka.bootstrapServers=hadoop1:9092,hadoop2:9092,hadoop3:9092
# 数据采集配置文件在hdfs上的路径
flink.hdfs.collector.conf-path=/flink/conf/
# 数据采集主jar包在hdfs上的路径
flink.hdfs.collector.job-jars-path=/flink/jobs/
# 数据采集主类名在hdfs上的路径
flink.hdfs.collector.jar-name=flink-jobs.jar
# 数据采集依赖在hdfs上的路径
flink.hdfs.collector.lib-path=/flink/libs
# 数据采集flink主jar包在hdfs上的路径
flink.hdfs.dist-jar-path=/flink/libs/flink-dist-1.16.2.jar
# savepoint默认路径
flink.default.savepoint.path=hdfs://hadoop1:9000/flink/savepoint/lacus/
# checkpoint默认路径，目前没有用到
flink.default.checkpoint.path=hdfs://hadoop1:9000/flink/checkpoint/lacus/
# flink streaming jar 包版本
flink.streaming.jarversion=lacus-flink-core-1.0.0-jar-with-dependencies.jar
# Local Cluster模式flink集群地址
flink.rest.http.address=http://localhost:4040
# Standalone Cluster模式flink集群地址
flink.rest.ha.http.address=http://hadoop1:8088
# 程序部署目录，为了执行flink或spark任务时生成临时文件 /opt/software/lacus/
lacus.application.home=/Users/casey/Data/lacus/
# 本地flink客户端路径 /opt/software/flink1.16.3/
flink.client.home=/Users/casey/Data/install/flink-1.16.2
# flink任务执行目录，用于生产临时文件 /opt/software/lacus/execute/flink/
flink.job.execute.home=/Users/casey/Data/install/flink-1.16.2/temp/
